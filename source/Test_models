import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from Train import training_single_model
from models.Initial_fc_nn import FC_single

# Set the random seed for reproducibility
np.random.seed(42)

# Load the data and define the loss function
data = np.load("data/Generated_Data/simulation_simple_0.0.npz")
model_class = FC_single
#loss = nn.MSELoss()
loss = nn.L1Loss()

# Initialize lists to collect the arrays
mean_percentage_diffs = []
std_percentage_diffs = []
for i in range(10):
    print(f"Training model {i + 1}")
    model, best_val_loss, mean_percentage_diff, std_percentage_diff = training_single_model(data, model_class, loss, batch_size=1028, lr=0.001, patience=5, epochs=50, progress=True)
    # Append the results to the lists
    mean_percentage_diffs.append(mean_percentage_diff)
    std_percentage_diffs.append(std_percentage_diff)

# Convert lists to 2D numpy arrays
mean_percentage_diffs_array = np.array(mean_percentage_diffs)
std_percentage_diffs_array = np.array(std_percentage_diffs)

# Calculate the average of each column
mean_percentage_diffs_avg = np.mean(mean_percentage_diffs_array, axis=0)
std_percentage_diffs_avg = np.mean(std_percentage_diffs_array, axis=0)

# Print the average values for each column
print("Average of mean percentage differences:", mean_percentage_diffs_avg)
print("Average of std percentage differences:", std_percentage_diffs_avg)

# Custom parameter labels
parameters = ['k1', 'k2', 'k3', 'vb']

# Plotting without connecting line
plt.figure(figsize=(10, 6))
# Error bars for the standard deviation
errorbar_container = plt.errorbar(parameters, mean_percentage_diffs_avg, 
             yerr=[np.zeros_like(std_percentage_diffs_avg), std_percentage_diffs_avg], 
             fmt='s', capsize=5, capthick=2, ecolor='red', markersize=5, 
             linestyle='None', label='Average Std')

# Annotating each point with its value
for i, txt in enumerate(mean_percentage_diffs_avg):
    plt.annotate(f'{txt:.2f}', (parameters[i], mean_percentage_diffs_avg[i]), textcoords="offset points", xytext=(25,0), ha='center')
for i, txt in enumerate(std_percentage_diffs_avg):
    plt.annotate(f'{txt:.2f}', (parameters[i], mean_percentage_diffs_avg[i] + std_percentage_diffs_avg[i]), textcoords="offset points", xytext=(25,0), ha='center')

# Extending the graph to the right by adjusting x-axis limits
plt.xlim(-0.25, len(parameters)-0.5)  # Set dynamic limits based on the number of parameters

# Customizing the plot
plt.title('Difference in predictions for a fully connected NN: L1 Loss & 10 models')
plt.xlabel('Parameter')
plt.ylabel('Mean Percentage Difference [%]')
plt.grid(True, which='both', linestyle='--', linewidth=0.5)

# Handling legend for both Average Difference and Average Std
plt.scatter(parameters, mean_percentage_diffs_avg, color='blue', label='Average Difference')
plt.legend(handles=[plt.Line2D([0], [0], marker='s', color='w', markerfacecolor='blue', markersize=5, label='Mean Percentage Difference'),
                    plt.Line2D([0], [0], marker='s', color='w', markerfacecolor='red', markersize=5, label='Mean Std of Percentage Difference')],
           loc='best')

# Show plot
plt.show()